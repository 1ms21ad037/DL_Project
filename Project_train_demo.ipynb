{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcZSVr2kNgxb",
        "outputId": "d4eac3bc-1f2b-41b2-9225-52c689526671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.15)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.43)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.18.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.11.4)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.4)\n",
            "Requirement already satisfied: torch<2.4,>=1.10 in /usr/local/lib/python3.10/dist-packages (from fastai) (2.3.0+cu121)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (4.66.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=1.10->fastai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.4,>=1.10->fastai) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.1.1)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install fastai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.data.external import untar_data, URLs\n",
        "coco_path = untar_data(URLs.COCO_SAMPLE)\n",
        "coco_path = str(coco_path) + \"/train_sample\"\n",
        "use_colab = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "iEoHW6YKNlOh",
        "outputId": "c29de217-7915-465e-bef5-8414c1831451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3245883392' class='' max='3245877008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [3245883392/3245877008 01:26&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "yolo_model = YOLO(\"yolov8x.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVy5rz9aN9oA",
        "outputId": "46ec3387-c279-46e9-95e5-f7b2ccaa8080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.31-py3-none-any.whl (780 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.6/780.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=0.2.5 (from ultralytics)\n",
            "  Downloading ultralytics_thop-0.2.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.31 ultralytics-thop-0.2.8\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 176MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "Path.ls = lambda x: list(x.iterdir())\n",
        "import cv2\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vhhyhj7qNnLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(yolo_model, image_path):\n",
        "    results = yolo_model(image_path)\n",
        "    return results"
      ],
      "metadata": {
        "id": "qtw55EL5Np4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = coco_path\n",
        "paths = glob.glob(path + \"/*.jpg\") # Your path for your dataset\n",
        "np.random.seed(123)\n",
        "paths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 1000 images randomly\n",
        "rand_idxs = np.random.permutation(10_000)\n",
        "train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\n",
        "val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\n",
        "train_paths = paths_subset[train_idxs]\n",
        "val_paths = paths_subset[val_idxs]\n",
        "print(len(train_paths), len(val_paths))"
      ],
      "metadata": {
        "id": "tHiNM8_EOgBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 256\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, paths, split='train'):\n",
        "        if split == 'train':\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(), # A little data augmentation!\n",
        "            ])\n",
        "        elif split == 'val':\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
        "\n",
        "        self.split = split\n",
        "        self.size = SIZE\n",
        "        self.paths = paths\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        results = detect_objects(yolo_model, self.paths[idx])\n",
        "\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "        img = np.array(img)\n",
        "        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n",
        "        img_lab = transforms.ToTensor()(img_lab)\n",
        "        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n",
        "        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
        "        detection_mask = self.process_detections(results, img_lab.shape[1:])\n",
        "\n",
        "        return {'L': L, 'ab': ab, 'detections': detection_mask}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def process_detections(self, detections, img_size):\n",
        "        mask = torch.zeros((1, img_size[0], img_size[1]))\n",
        "        for result in detections:\n",
        "            boxes = result.boxes.xyxy.tolist()\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                mask[:, y1:y2, x1:x2] = 1\n",
        "        return mask\n",
        "\n",
        "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs): # A handy function to make our dataloaders\n",
        "    dataset = ColorizationDataset(**kwargs)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
        "                            pin_memory=pin_memory)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "PKWo5nipOk1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = make_dataloaders(paths=train_paths, split='train')\n",
        "val_dl = make_dataloaders(paths=val_paths, split='val')"
      ],
      "metadata": {
        "id": "IsXm1zF_O8Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9659e003-f605-446f-c38e-82bc13c46aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
        "        super().__init__()\n",
        "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
        "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
        "                          for i in range(n_down)] # the 'if' statement is taking care of not using\n",
        "                                                  # stride of 2 for the last block in this loop\n",
        "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n",
        "                                                                                             # activation for the last layer of the model\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n",
        "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n",
        "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
        "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "H2ClYQtXO99-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.learner import create_body\n",
        "from torchvision.models.resnet import resnet18\n",
        "from fastai.vision.models.unet import DynamicUnet\n",
        "import torchvision\n",
        "resnet18_model = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = resnet18_model.fc.in_features\n",
        "n_output = 2\n",
        "resnet18_model.fc = nn.Linear(num_ftrs, n_output)"
      ],
      "metadata": {
        "id": "AS3WjVTdQ2pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed5ed1a-3938-407d-da30-12dca5a2aaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 91.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_res_unet(n_input=2, n_output=2, size=256):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    body = create_body(resnet18_model, pretrained=True, n_in=n_input, cut=-2)\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G"
      ],
      "metadata": {
        "id": "r8TOd-90Q5n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
        "    for e in range(epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        for data in tqdm(train_dl):\n",
        "            L, ab, detection_mask = data['L'].to(device), data['ab'].to(device), data['detections'].to(device)\n",
        "            L_with_mask = torch.cat([L, detection_mask], dim=1)  # Concatenate L channel and detection mask\n",
        "            preds = net_G(L_with_mask)\n",
        "            loss = criterion(preds, ab)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            loss_meter.update(loss.item(), L.size(0))\n",
        "\n",
        "        print(f\"Epoch {e + 1}/{epochs}\")\n",
        "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n",
        "\n",
        "net_G = build_res_unet(n_input=2, n_output=2, size=256)\n",
        "opt = optim.Adam(net_G.parameters(), lr=1e-4)\n",
        "criterion = nn.L1Loss()\n",
        "pretrain_generator(net_G, train_dl, opt, criterion, 1)"
      ],
      "metadata": {
        "id": "3pCYz_-EycJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def __call__(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "GErSPMKGP2ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(net, init='norm', gain=0.02):\n",
        "\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
        "            if init == 'norm':\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "            elif init == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif 'BatchNorm2d' in classname:\n",
        "            nn.init.normal_(m.weight.data, 1., gain)\n",
        "            nn.init.constant_(m.bias.data, 0.)\n",
        "\n",
        "    net.apply(init_func)\n",
        "    print(f\"model initialized with {init} initialization\")\n",
        "    return net\n",
        "\n",
        "def init_model(model, device):\n",
        "    model = model.to(device)\n",
        "    model = init_weights(model)\n",
        "    return model"
      ],
      "metadata": {
        "id": "6Gc5Z-isP5be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyEvoclPQ97E",
        "outputId": "9d16bb42-9b8e-4282-a16a-eb4a7edbfd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MainModel(nn.Module):\n",
        "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
        "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lambda_L1 = lambda_L1\n",
        "\n",
        "        self.net_G = net_G.to(self.device)\n",
        "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
        "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
        "        self.L1criterion = nn.L1Loss()\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "    def set_requires_grad(self, model, requires_grad=True):\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = requires_grad\n",
        "\n",
        "    def setup_input(self, data):\n",
        "        self.L = data['L'].to(self.device)\n",
        "        self.ab = data['ab'].to(self.device)\n",
        "\n",
        "    def forward(self):\n",
        "        self.fake_color = self.net_G(self.L)\n",
        "\n",
        "    def backward_D(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image.detach())\n",
        "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
        "        real_preds = self.net_D(real_image)\n",
        "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image)\n",
        "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize(self):\n",
        "        self.forward()\n",
        "        self.net_D.train()\n",
        "        self.set_requires_grad(self.net_D, True)\n",
        "        self.opt_D.zero_grad()\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "\n",
        "        self.net_G.train()\n",
        "        self.set_requires_grad(self.net_D, False)\n",
        "        self.opt_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()"
      ],
      "metadata": {
        "id": "U3AGedKTP77m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.count, self.avg, self.sum = [0.] * 3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += count * val\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def create_loss_meters():\n",
        "    loss_D_fake = AverageMeter()\n",
        "    loss_D_real = AverageMeter()\n",
        "    loss_D = AverageMeter()\n",
        "    loss_G_GAN = AverageMeter()\n",
        "    loss_G_L1 = AverageMeter()\n",
        "    loss_G = AverageMeter()\n",
        "\n",
        "    return {'loss_D_fake': loss_D_fake,\n",
        "            'loss_D_real': loss_D_real,\n",
        "            'loss_D': loss_D,\n",
        "            'loss_G_GAN': loss_G_GAN,\n",
        "            'loss_G_L1': loss_G_L1,\n",
        "            'loss_G': loss_G}\n",
        "\n",
        "def update_losses(model, loss_meter_dict, count):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        loss = getattr(model, loss_name)\n",
        "        loss_meter.update(loss.item(), count=count)\n",
        "\n",
        "def lab_to_rgb(L, ab):\n",
        "    \"\"\"\n",
        "    Takes a batch of images\n",
        "    \"\"\"\n",
        "\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def visualize(model, data, save=True):\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "    model.net_G.train()\n",
        "    fake_color = model.fake_color.detach()\n",
        "    real_color = model.ab\n",
        "    L = model.L\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "    if save:\n",
        "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
        "\n",
        "def log_results(loss_meter_dict):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
      ],
      "metadata": {
        "id": "dM4zPHXoQunm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dl, epochs, display_every=200):\n",
        "    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n",
        "    for e in range(epochs):\n",
        "        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to\n",
        "        i = 0                                  # log the losses of the complete network\n",
        "        for data in tqdm(train_dl):\n",
        "            model.setup_input(data)\n",
        "            model.optimize()\n",
        "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
        "            i += 1\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "                log_results(loss_meter_dict) # function to print out the losses\n",
        "                visualize(model, data, save=False) # function displaying the model's outputs\n"
      ],
      "metadata": {
        "id": "U7hNepqLQz-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_G.load_state_dict(torch.load(r\"/content/drive/MyDrive/saved_models/res18-unet.pt\", map_location=device))\n",
        "model = MainModel(net_G=net_G)\n",
        "train_model(model, train_dl, 1)"
      ],
      "metadata": {
        "id": "yeUYfMKbzBcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}